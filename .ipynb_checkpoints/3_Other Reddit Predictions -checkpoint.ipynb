{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Other Reddits\n",
    "\n",
    "In this notebook, I am going to take a look at what reddit posts characteristics most accurately predict which subreddits when the subreddits are about the same topic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, r2_score, accuracy_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import regex as re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./investing.csv', index_col=0)\n",
    "df2 = pd.read_csv('./stocks.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's moronic Monday, the Wednesday edition, yo...</td>\n",
       "      <td>We encourage all our visitors to ask those inv...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>investing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Musk Doubles Down On Cave Diver Attack, Calls ...</td>\n",
       "      <td>article: https://www.cnbc.com/2018/09/05/tesla...</td>\n",
       "      <td>LIFO_CAN_FIFO_ITSELF</td>\n",
       "      <td>investing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mercedes Unveils First Tesla Rival in $12 Bill...</td>\n",
       "      <td>Full article: [https://www.bloomberg.com/news/...</td>\n",
       "      <td>Throwawayacct449393</td>\n",
       "      <td>investing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norway's $1 trillion sovereign wealth fund is ...</td>\n",
       "      <td>https://www.cnbc.com/2018/09/05/norways-1-tril...</td>\n",
       "      <td>NineteenEighty9</td>\n",
       "      <td>investing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fidelity's New Zero Fee Funds Experience $1 Bi...</td>\n",
       "      <td>News article: https://www.cnbc.com/2018/09/04/...</td>\n",
       "      <td>notafeg</td>\n",
       "      <td>investing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  It's moronic Monday, the Wednesday edition, yo...   \n",
       "1  Musk Doubles Down On Cave Diver Attack, Calls ...   \n",
       "2  Mercedes Unveils First Tesla Rival in $12 Bill...   \n",
       "3  Norway's $1 trillion sovereign wealth fund is ...   \n",
       "4  Fidelity's New Zero Fee Funds Experience $1 Bi...   \n",
       "\n",
       "                                                post                author  \\\n",
       "0  We encourage all our visitors to ask those inv...         AutoModerator   \n",
       "1  article: https://www.cnbc.com/2018/09/05/tesla...  LIFO_CAN_FIFO_ITSELF   \n",
       "2  Full article: [https://www.bloomberg.com/news/...   Throwawayacct449393   \n",
       "3  https://www.cnbc.com/2018/09/05/norways-1-tril...       NineteenEighty9   \n",
       "4  News article: https://www.cnbc.com/2018/09/04/...               notafeg   \n",
       "\n",
       "   subreddit  \n",
       "0  investing  \n",
       "1  investing  \n",
       "2  investing  \n",
       "3  investing  \n",
       "4  investing  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check \n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>LGORF - what do you guys think?</td>\n",
       "      <td>Was listening to a Bloomberg show, it was an h...</td>\n",
       "      <td>HariOfTrantor</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>the stars group</td>\n",
       "      <td>r/https://thestockboys.com/2018/08/13/time-to-...</td>\n",
       "      <td>matttttt123</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>Opinions on FLWS</td>\n",
       "      <td>1800 flowers was an early adopter for e-commer...</td>\n",
       "      <td>DeliciouslyUnaware</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>SUNRUN to RUN UP?</td>\n",
       "      <td>Since their earnings report where SUNRUN disap...</td>\n",
       "      <td>Scarecroll</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>Is SPOT overvalued?</td>\n",
       "      <td>I feel like it’s going to be very difficult fo...</td>\n",
       "      <td>84935</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "791  LGORF - what do you guys think?   \n",
       "792                  the stars group   \n",
       "793                 Opinions on FLWS   \n",
       "794                SUNRUN to RUN UP?   \n",
       "795              Is SPOT overvalued?   \n",
       "\n",
       "                                                  post              author  \\\n",
       "791  Was listening to a Bloomberg show, it was an h...       HariOfTrantor   \n",
       "792  r/https://thestockboys.com/2018/08/13/time-to-...         matttttt123   \n",
       "793  1800 flowers was an early adopter for e-commer...  DeliciouslyUnaware   \n",
       "794  Since their earnings report where SUNRUN disap...          Scarecroll   \n",
       "795  I feel like it’s going to be very difficult fo...               84935   \n",
       "\n",
       "    subreddit  \n",
       "791    stocks  \n",
       "792    stocks  \n",
       "793    stocks  \n",
       "794    stocks  \n",
       "795    stocks  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(968, 4)\n",
      "(796, 4)\n",
      "1764\n"
     ]
    }
   ],
   "source": [
    "#print to see how many rows\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "print(968+796)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat the two df\n",
    "all_df = [df1, df2]\n",
    "df = pd.concat(all_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1764, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm final shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change target column to binary so talesfromtech will be 1 and jokes will be 0\n",
    "df['subreddit'] = [1 if i == 'investing' else 0 for i in df['subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to make sure it works\n",
    "# df.head()\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check what our titles look like\n",
    "# df['title'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check what our posts look like\n",
    "# df['Post'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a raw post to a string of words\n",
    "def raw_to_words(raw):\n",
    "    \n",
    "    #remove URL\n",
    "    link = re.sub(r'http\\S+', '', raw)\n",
    "    \n",
    "    # Remove HTML\n",
    "    text = BeautifulSoup(link).get_text()\n",
    "    \n",
    "    # Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    \n",
    "    # Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    # convert the stop words to a set\n",
    "    stops = set(stopwords.words('english'))\n",
    "    \n",
    "    # Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    # Join the words back into one string separated by space and return the result.\n",
    "    return (\" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'encourage visitors ask investing related questions always afraid ask members r investing answer educate note question anything similar single answer question also need lot information give sort answer old employed making income much objectives money buy house retirement savings risk tolerance mind risking blackjack need know safe current holdings already exposure specific funds sectors assets house paid cars expensive girlfriend really asset time horizon need money next month next yrs big debts relevant financial information useful give proper answer aware answers opinions redditors used starting point research strongly consider seeing registered financial rep making financial decisions'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check first post to see if it worked\n",
    "raw_to_words(df['post'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1714, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop null values\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply data cleaning function to columns\n",
    "df['title'] = df['title'].map(raw_to_words)\n",
    "df['post'] = df['post'].map(raw_to_words)\n",
    "df['author'] = df['author'].map(raw_to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.536173\n",
       "0    0.463827\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at baseline accuracy, majority looks like it is talesfromtechsupport with 52.3%\n",
    "# we would want something at least greater than this.\n",
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title Column\n",
    "\n",
    "I am going to start with the title column and see how just the title does in predicting subreddit talesfromtechsupport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set X and y to run train test split for title\n",
    "X_title = df.title\n",
    "y = df.subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_title , y , test_size = .33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n-gram = 1\n",
    "cvec = CountVectorizer(stop_words='english', max_features = 5000, ngram_range=(1,1)).fit(X_train)\n",
    "df_train = pd.DataFrame(cvec.transform(X_train).todense(), columns=cvec.get_feature_names())\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).todense(), columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n-gram = 2\n",
    "cvec = CountVectorizer(stop_words='english', max_features = 5000, ngram_range=(1,2)).fit(X_train)\n",
    "df_train_2 = pd.DataFrame(cvec.transform(X_train).todense(), columns=cvec.get_feature_names())\n",
    "df_test_2 = pd.DataFrame(cvec.transform(X_test).todense(), columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n-gram = 1\n",
    "tvec = TfidfVectorizer(stop_words='english', ngram_range=(1,1)).fit(X_train)\n",
    "train_title = pd.DataFrame(tvec.transform(X_train).todense(), columns = tvec.get_feature_names())\n",
    "test_title = pd.DataFrame(tvec.transform(X_test).todense(), columns = tvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n-gram = 2\n",
    "tvec = TfidfVectorizer(stop_words='english', ngram_range=(1,2)).fit(X_train)\n",
    "train_title_2 = pd.DataFrame(tvec.transform(X_train).todense(), columns = tvec.get_feature_names())\n",
    "test_title_2 = pd.DataFrame(tvec.transform(X_test).todense(), columns = tvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe to store my accuracy scores along the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set columns and index for the df\n",
    "columns = ['cvec_score_1', 'cvec_score_2', 'tvec_score_1', 'tvec_score_2']\n",
    "index = ['lr_title', 'knn_title', 'randomforest_title', 'multinomial_title',\n",
    "         'lr_post', 'knn_post', 'randomforest_post', 'multinomial_post',\n",
    "         'lr_title_post', 'knn_title_post', 'randomforest_title_post', 'multinomial_title_post']\n",
    "score_df = pd.DataFrame(index=index,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6254416961130742\n",
      "train score 0.9259581881533101\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 1, CVEC\n",
    "lr = LogisticRegression()\n",
    "lr.fit(df_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(df_test)\n",
    "score_df['cvec_score_1']['lr_title'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', lr.score(df_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6183745583038869\n",
      "train score 0.9729965156794426\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 2, CVEC\n",
    "lr = LogisticRegression()\n",
    "lr.fit(df_train_2, y_train)\n",
    "\n",
    "y_pred = lr.predict(df_test_2)\n",
    "score_df['cvec_score_2']['lr_title'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', lr.score(df_train_2, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6254416961130742\n",
      "train score 0.877177700348432\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 1, TVEC\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_title, y_train)\n",
    "\n",
    "y_pred = lr.predict(test_title)\n",
    "score_df['tvec_score_1']['lr_title'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', lr.score(train_title, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.627208480565371\n",
      "train score 0.9468641114982579\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 2, TVEC\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_title_2, y_train)\n",
    "\n",
    "y_pred = lr.predict(test_title_2)\n",
    "score_df['tvec_score_2']['lr_title'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', lr.score(train_title_2, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.5848056537102474\n",
      "train score 0.9912891986062717\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 1, CVEC\n",
    "params = {\n",
    "    'n_neighbors': (1, 3, 5),\n",
    "    'metric': ['minkowski', 'euclidean'],\n",
    "    'weights': ['uniform', 'distance']    \n",
    "}\n",
    "gs = GridSearchCV(KNeighborsClassifier(), params)\n",
    "gs.fit(df_train, y_train)\n",
    "\n",
    "y_pred = gs.predict(df_test)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', gs.score(df_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df['cvec_score_1']['knn_title'] = 0.5848056537102474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.5742049469964664\n",
      "train score 0.9886759581881533\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 2, CVEC\n",
    "params = {\n",
    "    'n_neighbors': (1, 3, 5),\n",
    "    'metric': ['minkowski', 'euclidean'],\n",
    "    'weights': ['uniform', 'distance']    \n",
    "}\n",
    "gs = GridSearchCV(KNeighborsClassifier(), params)\n",
    "gs.fit(df_train_2, y_train)\n",
    "\n",
    "y_pred = gs.predict(df_test_2)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', gs.score(df_train_2, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df['cvec_score_2']['knn_title'] = 0.5742049469964664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.598939929328622\n",
      "train score 0.9912891986062717\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 1, TVEC\n",
    "params = {\n",
    "    'n_neighbors': (1, 3, 5),\n",
    "    'metric': ['minkowski', 'euclidean'],\n",
    "    'weights': ['uniform', 'distance']    \n",
    "}\n",
    "gs = GridSearchCV(KNeighborsClassifier(), params)\n",
    "gs.fit(train_title, y_train)\n",
    "\n",
    "y_pred = gs.predict(test_title)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', gs.score(train_title, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df['tvec_score_1']['knn_title'] = 0.598939929328622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.588339222614841\n",
      "train score 0.7560975609756098\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 2, TVEC\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(train_title_2, y_train)\n",
    "\n",
    "y_pred = knn.predict(test_title_2)\n",
    "score_df['tvec_score_2']['knn_title'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', knn.score(train_title_2, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7229965156794426\n",
      "0.6095406360424028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced', 'max_depth': 6, 'n_estimators': 50}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#n-gram = 1, CVEC\n",
    "rf_param={\n",
    "    'class_weight': ['balanced'],\n",
    "    'n_estimators': (45, 50, 55),\n",
    "    'max_depth': [5, 6]\n",
    "}\n",
    "rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=rf_param)\n",
    "rf.fit(df_train, y_train)\n",
    "\n",
    "score_df['cvec_score_1']['randomforest_title'] = rf.score(df_test, y_test)\n",
    "print(rf.score(df_train, y_train))\n",
    "print(rf.score(df_test, y_test))\n",
    "rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7151567944250871\n",
      "0.6007067137809188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced', 'max_depth': 6, 'n_estimators': 55}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#n-gram = 2, CVEC\n",
    "rf_param={\n",
    "    'class_weight': ['balanced'],\n",
    "    'n_estimators': (45, 50, 55),\n",
    "    'max_depth': [5, 6]\n",
    "}\n",
    "rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=rf_param)\n",
    "rf.fit(df_train_2, y_train)\n",
    "\n",
    "score_df['cvec_score_2']['randomforest_title'] = rf.score(df_test_2, y_test)\n",
    "print(rf.score(df_train_2, y_train))\n",
    "print(rf.score(df_test_2, y_test))\n",
    "rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7264808362369338\n",
      "0.5848056537102474\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 1, TVEC\n",
    "rf_param={\n",
    "    'class_weight': ['balanced'],\n",
    "    'n_estimators': (45, 50, 55),\n",
    "    'max_depth': [5, 6]\n",
    "}\n",
    "rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=rf_param)\n",
    "rf.fit(train_title, y_train)\n",
    "\n",
    "score_df['tvec_score_1']['randomforest_title'] = rf.score(test_title, y_test)\n",
    "print(rf.score(train_title, y_train))\n",
    "print(rf.score(test_title, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.730836236933798\n",
      "0.6166077738515902\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 2, TVEC\n",
    "rf_param={\n",
    "    'class_weight': ['balanced'],\n",
    "    'n_estimators': (45, 50, 55),\n",
    "    'max_depth': [5, 6]\n",
    "}\n",
    "rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=rf_param)\n",
    "rf.fit(train_title_2, y_train)\n",
    "\n",
    "score_df['tvec_score_2']['randomforest_title'] = rf.score(test_title_2, y_test)\n",
    "print(rf.score(train_title_2, y_train))\n",
    "print(rf.score(test_title_2, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6148409893992933\n",
      "train score 0.89198606271777\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 1, CVEC\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(df_train, y_train)\n",
    "\n",
    "y_pred = mnb.predict(df_test)\n",
    "score_df['cvec_score_1']['multinomial_title'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', mnb.score(df_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6130742049469965\n",
      "train score 0.9425087108013938\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 2, CVEC\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(df_train_2, y_train)\n",
    "\n",
    "y_pred = mnb.predict(df_test_2)\n",
    "score_df['cvec_score_2']['multinomial_title'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', mnb.score(df_train_2, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6219081272084805\n",
      "train score 0.9102787456445993\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 1, TVEC\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_title, y_train)\n",
    "\n",
    "y_pred = mnb.predict(test_title)\n",
    "score_df['tvec_score_1']['multinomial_title'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', mnb.score(train_title, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6219081272084805\n",
      "train score 0.9695121951219512\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 2, TVEC\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_title_2, y_train)\n",
    "\n",
    "y_pred = mnb.predict(test_title_2)\n",
    "score_df['tvec_score_2']['multinomial_title'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', mnb.score(train_title_2, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Column\n",
    "Next I am going to take a look at just the post texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set x and y for train test split\n",
    "X_post = df.post\n",
    "y = df.subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_post, y, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n-gram = 1\n",
    "cvec = CountVectorizer(stop_words='english', max_features = 5000, ngram_range=(1,1)).fit(X_train)\n",
    "cvec_train_post = pd.DataFrame(cvec.transform(X_train).todense(), columns=cvec.get_feature_names())\n",
    "cvec_test_post = pd.DataFrame(cvec.transform(X_test).todense(), columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n-gram = 2\n",
    "cvec_2 = CountVectorizer(stop_words='english', max_features = 5000, ngram_range=(1,2)).fit(X_train)\n",
    "cvec_train_post_2 = pd.DataFrame(cvec_2.transform(X_train).todense(), columns=cvec_2.get_feature_names())\n",
    "cvec_test_post_2 = pd.DataFrame(cvec_2.transform(X_test).todense(), columns=cvec_2.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n-gram = 1\n",
    "tvec = TfidfVectorizer(stop_words='english', ngram_range=(1,1)).fit(X_train)\n",
    "tvec_train_post = pd.DataFrame(tvec.transform(X_train).todense(), columns = tvec.get_feature_names())\n",
    "tvec_test_post = pd.DataFrame(tvec.transform(X_test).todense(), columns = tvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n-gram = 2\n",
    "tvec_2 = TfidfVectorizer(stop_words='english', ngram_range=(1,2)).fit(X_train)\n",
    "tvec_train_post_2 = pd.DataFrame(tvec_2.transform(X_train).todense(), columns = tvec_2.get_feature_names())\n",
    "tvec_test_post_2 = pd.DataFrame(tvec_2.transform(X_test).todense(), columns = tvec_2.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6254416961130742\n",
      "train score 0.9799651567944251\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 1, CVEC\n",
    "lr = LogisticRegression()\n",
    "lr.fit(cvec_train_post, y_train)\n",
    "\n",
    "y_pred = lr.predict(cvec_test_post)\n",
    "score_df['cvec_score_1']['lr_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', lr.score(cvec_train_post, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6201413427561837\n",
      "train score 0.9860627177700348\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 2, CVEC\n",
    "lr = LogisticRegression()\n",
    "lr.fit(cvec_train_post_2, y_train)\n",
    "\n",
    "y_pred = lr.predict(cvec_test_post_2)\n",
    "score_df['cvec_score_2']['lr_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', lr.score(cvec_train_post_2, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6342756183745583\n",
      "train score 0.8998257839721254\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 1, TVEC\n",
    "lr = LogisticRegression()\n",
    "lr.fit(tvec_train_post, y_train)\n",
    "\n",
    "y_pred = lr.predict(tvec_test_post)\n",
    "score_df['tvec_score_1']['lr_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', lr.score(tvec_train_post, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6484098939929329\n",
      "train score 0.9817073170731707\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 2, TVEC\n",
    "lr = LogisticRegression()\n",
    "lr.fit(tvec_train_post_2, y_train)\n",
    "\n",
    "y_pred = lr.predict(tvec_test_post_2)\n",
    "score_df['tvec_score_2']['lr_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', lr.score(tvec_train_post_2, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.5335689045936396\n",
      "train score 0.6332752613240418\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 1, CVEC\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(cvec_train_post, y_train)\n",
    "\n",
    "y_pred = knn.predict(cvec_test_post)\n",
    "score_df['cvec_score_1']['knn_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', knn.score(cvec_train_post, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.5300353356890459\n",
      "train score 0.6332752613240418\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 2, CVEC\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(cvec_train_post_2, y_train)\n",
    "\n",
    "y_pred = knn.predict(cvec_test_post_2)\n",
    "score_df['cvec_score_2']['knn_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', knn.score(cvec_train_post_2, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.5547703180212014\n",
      "train score 0.5574912891986062\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 1, TVEC\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(tvec_train_post, y_train)\n",
    "\n",
    "y_pred = knn.predict(tvec_test_post)\n",
    "score_df['tvec_score_1']['knn_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', knn.score(tvec_train_post, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7682926829268293\n",
      "0.6201413427561837\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 1, CVEC\n",
    "rf_param={\n",
    "    'class_weight': ['balanced'],\n",
    "    'n_estimators': (45, 50, 55),\n",
    "    'max_depth': [5, 6]\n",
    "}\n",
    "rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=rf_param)\n",
    "rf.fit(cvec_train_post, y_train)\n",
    "\n",
    "score_df['cvec_score_1']['randomforest_post'] = rf.score(cvec_test_post, y_test)\n",
    "print(rf.score(cvec_train_post, y_train))\n",
    "print(rf.score(cvec_test_post, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.789198606271777\n",
      "0.6325088339222615\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 2, CVEC\n",
    "rf_param={\n",
    "    'class_weight': ['balanced'],\n",
    "    'n_estimators': (45, 50, 55),\n",
    "    'max_depth': [5, 6]\n",
    "}\n",
    "rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=rf_param)\n",
    "rf.fit(cvec_train_post_2, y_train)\n",
    "\n",
    "score_df['cvec_score_2']['randomforest_post'] = rf.score(cvec_test_post_2, y_test)\n",
    "print(rf.score(cvec_train_post_2, y_train))\n",
    "print(rf.score(cvec_test_post_2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8275261324041812\n",
      "0.6431095406360424\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 1, TVEC\n",
    "rf_param={\n",
    "    'class_weight': ['balanced'],\n",
    "    'n_estimators': (45, 50, 55),\n",
    "    'max_depth': [5, 6]\n",
    "}\n",
    "rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=rf_param)\n",
    "rf.fit(tvec_train_post, y_train)\n",
    "\n",
    "score_df['tvec_score_1']['randomforest_post'] = rf.score(tvec_test_post, y_test)\n",
    "print(rf.score(tvec_train_post, y_train))\n",
    "print(rf.score(tvec_test_post, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7761324041811847\n",
      "0.6113074204946997\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 2, TVEC\n",
    "rf_param={\n",
    "    'class_weight': ['balanced'],\n",
    "    'n_estimators': (45, 50, 55),\n",
    "    'max_depth': [5, 6]\n",
    "}\n",
    "rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=rf_param)\n",
    "rf.fit(tvec_train_post_2, y_train)\n",
    "\n",
    "score_df['tvec_score_2']['randomforest_post'] = rf.score(tvec_test_post_2, y_test)\n",
    "print(rf.score(tvec_train_post_2, y_train))\n",
    "print(rf.score(tvec_test_post_2, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial NB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6607773851590106\n",
      "train score 0.8623693379790941\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 1, CVEC\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(cvec_train_post, y_train)\n",
    "\n",
    "y_pred = mnb.predict(cvec_test_post)\n",
    "score_df['cvec_score_1']['multinomial_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', mnb.score(cvec_train_post, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6431095406360424\n",
      "train score 0.8527874564459931\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 2, CVEC\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(cvec_train_post_2, y_train)\n",
    "\n",
    "y_pred = mnb.predict(cvec_test_post_2)\n",
    "score_df['cvec_score_2']['multinomial_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', mnb.score(cvec_train_post_2, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6607773851590106\n",
      "train score 0.9250871080139372\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 1, TVEC\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(tvec_train_post, y_train)\n",
    "\n",
    "y_pred = mnb.predict(tvec_test_post)\n",
    "score_df['tvec_score_1']['multinomial_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', mnb.score(tvec_train_post, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6554770318021201\n",
      "train score 0.990418118466899\n"
     ]
    }
   ],
   "source": [
    "#n-gram = 2, TVEC\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(tvec_train_post_2, y_train)\n",
    "\n",
    "y_pred = mnb.predict(tvec_test_post_2)\n",
    "score_df['tvec_score_2']['multinomial_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', mnb.score(tvec_train_post_2, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title and Post\n",
    "Lastly, lets take a look at title and post texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [],
   "source": [
    "#concat cvec of title and post for train and test\n",
    "cvec_title_post_train = pd.concat([cvec_train_post, df_train], axis = 1)\n",
    "cvec_title_post_test = pd.concat([cvec_test_post, df_test], axis = 1)\n",
    "\n",
    "#concat tvec of title and post for train and test\n",
    "tvec_title_post_train = pd.concat([tvec_train_post, train_title], axis = 1)\n",
    "tvec_title_post_test = pd.concat([tvec_test_post, test_title], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I didn't bother running n-grams = 2 for title and post\n",
    "# because it seemed like from title and post n-gram=2 didn't improve the score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.627208480565371\n",
      "train score 0.9947735191637631\n"
     ]
    }
   ],
   "source": [
    "#cvec\n",
    "lr = LogisticRegression()\n",
    "lr.fit(cvec_title_post_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(cvec_title_post_test)\n",
    "score_df['cvec_score_1']['lr_title_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', lr.score(cvec_title_post_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6554770318021201\n",
      "train score 0.955574912891986\n"
     ]
    }
   ],
   "source": [
    "#tvec\n",
    "lr = LogisticRegression()\n",
    "lr.fit(tvec_title_post_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(tvec_title_post_test)\n",
    "score_df['tvec_score_1']['lr_title_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', lr.score(tvec_title_post_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.5282685512367491\n",
      "train score 0.740418118466899\n"
     ]
    }
   ],
   "source": [
    "#cvec\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(cvec_title_post_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(cvec_title_post_test)\n",
    "score_df['cvec_score_1']['knn_title_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', knn.score(cvec_title_post_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.5865724381625441\n",
      "train score 0.6045296167247387\n"
     ]
    }
   ],
   "source": [
    "#tvec\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(tvec_title_post_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(tvec_title_post_test)\n",
    "score_df['tvec_score_1']['knn_title_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', knn.score(tvec_title_post_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7987804878048781\n",
      "0.6325088339222615\n"
     ]
    }
   ],
   "source": [
    "#cvec\n",
    "rf_param={\n",
    "    'class_weight': ['balanced'],\n",
    "    'n_estimators': (45, 50, 55),\n",
    "    'max_depth': [5, 6]\n",
    "}\n",
    "rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=rf_param)\n",
    "rf.fit(cvec_title_post_train, y_train)\n",
    "\n",
    "score_df['cvec_score_1']['randomforest_title_post'] = rf.score(cvec_title_post_test, y_test)\n",
    "print(rf.score(cvec_title_post_train, y_train))\n",
    "print(rf.score(cvec_title_post_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8170731707317073\n",
      "0.6749116607773852\n"
     ]
    }
   ],
   "source": [
    "#tvec\n",
    "rf_param={\n",
    "    'class_weight': ['balanced'],\n",
    "    'n_estimators': (45, 50, 55),\n",
    "    'max_depth': [5, 6]\n",
    "}\n",
    "rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=rf_param)\n",
    "rf.fit(tvec_title_post_train, y_train)\n",
    "\n",
    "score_df['tvec_score_1']['randomforest_title_post'] = rf.score(tvec_title_post_test, y_test)\n",
    "print(rf.score(tvec_title_post_train, y_train))\n",
    "print(rf.score(tvec_title_post_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial NB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6713780918727915\n",
      "train score 0.9146341463414634\n"
     ]
    }
   ],
   "source": [
    "#cvec\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(cvec_title_post_train, y_train)\n",
    "\n",
    "y_pred = mnb.predict(cvec_title_post_test)\n",
    "score_df['cvec_score_1']['multinomial_title_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', mnb.score(cvec_title_post_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.6819787985865724\n",
      "train score 0.9451219512195121\n"
     ]
    }
   ],
   "source": [
    "#tvec\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(tvec_title_post_train, y_train)\n",
    "\n",
    "y_pred = mnb.predict(tvec_title_post_test)\n",
    "score_df['tvec_score_1']['multinomial_title_post'] = accuracy_score(y_test, y_pred)\n",
    "print('accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('train score', mnb.score(tvec_title_post_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Table\n",
    "Lets look at them all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvec_score_1</th>\n",
       "      <th>cvec_score_2</th>\n",
       "      <th>tvec_score_1</th>\n",
       "      <th>tvec_score_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr_title</th>\n",
       "      <td>0.625442</td>\n",
       "      <td>0.618375</td>\n",
       "      <td>0.625442</td>\n",
       "      <td>0.627208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_title</th>\n",
       "      <td>0.584806</td>\n",
       "      <td>0.574205</td>\n",
       "      <td>0.59894</td>\n",
       "      <td>0.588339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest_title</th>\n",
       "      <td>0.609541</td>\n",
       "      <td>0.600707</td>\n",
       "      <td>0.584806</td>\n",
       "      <td>0.616608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multinomial_title</th>\n",
       "      <td>0.614841</td>\n",
       "      <td>0.613074</td>\n",
       "      <td>0.621908</td>\n",
       "      <td>0.621908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_post</th>\n",
       "      <td>0.625442</td>\n",
       "      <td>0.620141</td>\n",
       "      <td>0.634276</td>\n",
       "      <td>0.64841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_post</th>\n",
       "      <td>0.533569</td>\n",
       "      <td>0.530035</td>\n",
       "      <td>0.55477</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest_post</th>\n",
       "      <td>0.620141</td>\n",
       "      <td>0.632509</td>\n",
       "      <td>0.64311</td>\n",
       "      <td>0.611307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multinomial_post</th>\n",
       "      <td>0.660777</td>\n",
       "      <td>0.64311</td>\n",
       "      <td>0.660777</td>\n",
       "      <td>0.655477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_title_post</th>\n",
       "      <td>0.627208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655477</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_title_post</th>\n",
       "      <td>0.528269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.586572</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest_title_post</th>\n",
       "      <td>0.632509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.674912</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multinomial_title_post</th>\n",
       "      <td>0.671378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681979</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        cvec_score_1 cvec_score_2 tvec_score_1 tvec_score_2\n",
       "lr_title                    0.625442     0.618375     0.625442     0.627208\n",
       "knn_title                   0.584806     0.574205      0.59894     0.588339\n",
       "randomforest_title          0.609541     0.600707     0.584806     0.616608\n",
       "multinomial_title           0.614841     0.613074     0.621908     0.621908\n",
       "lr_post                     0.625442     0.620141     0.634276      0.64841\n",
       "knn_post                    0.533569     0.530035      0.55477          NaN\n",
       "randomforest_post           0.620141     0.632509      0.64311     0.611307\n",
       "multinomial_post            0.660777      0.64311     0.660777     0.655477\n",
       "lr_title_post               0.627208          NaN     0.655477          NaN\n",
       "knn_title_post              0.528269          NaN     0.586572          NaN\n",
       "randomforest_title_post     0.632509          NaN     0.674912          NaN\n",
       "multinomial_title_post      0.671378          NaN     0.681979          NaN"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvec_score_1</th>\n",
       "      <th>tvec_score_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr_title</th>\n",
       "      <td>0.625442</td>\n",
       "      <td>0.625442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_title</th>\n",
       "      <td>0.584806</td>\n",
       "      <td>0.59894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest_title</th>\n",
       "      <td>0.609541</td>\n",
       "      <td>0.584806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multinomial_title</th>\n",
       "      <td>0.614841</td>\n",
       "      <td>0.621908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_post</th>\n",
       "      <td>0.625442</td>\n",
       "      <td>0.634276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_post</th>\n",
       "      <td>0.533569</td>\n",
       "      <td>0.55477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest_post</th>\n",
       "      <td>0.620141</td>\n",
       "      <td>0.64311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multinomial_post</th>\n",
       "      <td>0.660777</td>\n",
       "      <td>0.660777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_title_post</th>\n",
       "      <td>0.627208</td>\n",
       "      <td>0.655477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_title_post</th>\n",
       "      <td>0.528269</td>\n",
       "      <td>0.586572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest_title_post</th>\n",
       "      <td>0.632509</td>\n",
       "      <td>0.674912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multinomial_title_post</th>\n",
       "      <td>0.671378</td>\n",
       "      <td>0.681979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        cvec_score_1 tvec_score_1\n",
       "lr_title                    0.625442     0.625442\n",
       "knn_title                   0.584806      0.59894\n",
       "randomforest_title          0.609541     0.584806\n",
       "multinomial_title           0.614841     0.621908\n",
       "lr_post                     0.625442     0.634276\n",
       "knn_post                    0.533569      0.55477\n",
       "randomforest_post           0.620141      0.64311\n",
       "multinomial_post            0.660777     0.660777\n",
       "lr_title_post               0.627208     0.655477\n",
       "knn_title_post              0.528269     0.586572\n",
       "randomforest_title_post     0.632509     0.674912\n",
       "multinomial_title_post      0.671378     0.681979"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#going to take a look only at n-gram= 1\n",
    "drop = ['cvec_score_2', 'tvec_score_2']\n",
    "score_df.drop(score_df[drop], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients for best Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04794514, -0.01684372, -0.2113701 , ...,  0.08351664,\n",
       "        -0.40051824, -0.30824188]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#picked my top model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(tvec_title_post_train, y_train)\n",
    "y_pred = lr.predict(tvec_title_post_test)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish an array for my features so that i can match it with my coef_\n",
    "features = np.array(list(tvec_title_post_train)).reshape(-1,1)\n",
    "\n",
    "#to round my coef numbers and shape it to be same as my features\n",
    "coeffs = np.reshape(np.round(lr.coef_,5),(-1,1))\n",
    "# concat the two arrays together \n",
    "coeffs = np.concatenate((features,coeffs),axis=1)\n",
    "\n",
    "#put it back into a data frame to sort the values\n",
    "coef_df = pd.DataFrame(coeffs,columns=['Features','Coeff'])\n",
    "coef_df = coef_df.sort_values('Coeff', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Features    object\n",
       "Coeff       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check type\n",
    "coef_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert coeff to float\n",
    "coef_df['Coeff'] = coef_df['Coeff'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df['log_odds'] = np.exp(coef_df['Coeff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coeff</th>\n",
       "      <th>log_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>joined</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>1.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>investing</td>\n",
       "      <td>1.55938</td>\n",
       "      <td>4.755872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>fund</td>\n",
       "      <td>1.17216</td>\n",
       "      <td>3.228960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7206</th>\n",
       "      <td>china</td>\n",
       "      <td>0.99917</td>\n",
       "      <td>2.716027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8955</th>\n",
       "      <td>value</td>\n",
       "      <td>0.94490</td>\n",
       "      <td>2.572556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7825</th>\n",
       "      <td>index</td>\n",
       "      <td>0.93907</td>\n",
       "      <td>2.557602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>article</td>\n",
       "      <td>0.88087</td>\n",
       "      <td>2.412998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882</th>\n",
       "      <td>money</td>\n",
       "      <td>0.87708</td>\n",
       "      <td>2.403870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8805</th>\n",
       "      <td>tech</td>\n",
       "      <td>0.81911</td>\n",
       "      <td>2.268480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7409</th>\n",
       "      <td>dis</td>\n",
       "      <td>0.81584</td>\n",
       "      <td>2.261074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8156</th>\n",
       "      <td>new</td>\n",
       "      <td>0.81174</td>\n",
       "      <td>2.251823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6658</th>\n",
       "      <td>way</td>\n",
       "      <td>0.78515</td>\n",
       "      <td>2.192736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>risk</td>\n",
       "      <td>0.78000</td>\n",
       "      <td>2.181472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>need</td>\n",
       "      <td>0.73901</td>\n",
       "      <td>2.093862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>edit</td>\n",
       "      <td>0.73444</td>\n",
       "      <td>2.084314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Features    Coeff  log_odds\n",
       "3254     joined  0.00003  1.000030\n",
       "7871  investing  1.55938  4.755872\n",
       "2463       fund  1.17216  3.228960\n",
       "7206      china  0.99917  2.716027\n",
       "8955      value  0.94490  2.572556\n",
       "7825      index  0.93907  2.557602\n",
       "348     article  0.88087  2.412998\n",
       "3882      money  0.87708  2.403870\n",
       "8805       tech  0.81911  2.268480\n",
       "7409        dis  0.81584  2.261074\n",
       "8156        new  0.81174  2.251823\n",
       "6658        way  0.78515  2.192736\n",
       "5170       risk  0.78000  2.181472\n",
       "3981       need  0.73901  2.093862\n",
       "1890       edit  0.73444  2.084314"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check our coef df\n",
    "coef_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted stocks</th>\n",
       "      <th>predicted investing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual stocks</th>\n",
       "      <td>142</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual investing</th>\n",
       "      <td>72</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  predicted stocks  predicted investing\n",
       "actual stocks                  142                  123\n",
       "actual investing                72                  229"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set it into a dataframe for asthetics \n",
    "cm_df = pd.DataFrame(cm, columns=['predicted stocks', 'predicted investing'], \n",
    "                     index=['actual stocks', 'actual investing'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set classifications for each cell\n",
    "tn, fp, fn, tp = cm.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6554770318021201\n",
      "Misclassification: 0.34452296819787986\n",
      "Sensitivity: 0.760797342192691\n",
      "Specificity: 0.5358490566037736\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "misclassification = 1 - accuracy\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Misclassification:', misclassification)\n",
    "print('Sensitivity:', sensitivity)\n",
    "print('Specificity:', specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
